{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:36:56.900291Z",
     "iopub.status.busy": "2022-05-28T19:36:56.899406Z",
     "iopub.status.idle": "2022-05-28T19:37:02.717251Z",
     "shell.execute_reply": "2022-05-28T19:37:02.716379Z",
     "shell.execute_reply.started": "2022-05-28T19:36:56.900204Z"
    },
    "papermill": {
     "duration": 3.96448,
     "end_time": "2021-09-08T05:25:12.733999",
     "exception": false,
     "start_time": "2021-09-08T05:25:08.769519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:37:02.719642Z",
     "iopub.status.busy": "2022-05-28T19:37:02.719080Z",
     "iopub.status.idle": "2022-05-28T19:37:02.724575Z",
     "shell.execute_reply": "2022-05-28T19:37:02.723804Z",
     "shell.execute_reply.started": "2022-05-28T19:37:02.719614Z"
    },
    "papermill": {
     "duration": 0.021659,
     "end_time": "2021-09-08T05:25:12.770204",
     "exception": false,
     "start_time": "2021-09-08T05:25:12.748545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "DATA_PATH_PREFIX = '../input/satellite-data/'\n",
    "\n",
    "N_BANDS = 8    # input channel shape\n",
    "N_CLASSES = 5  # buildings, roads, trees, crops and water\n",
    "CLASS_WEIGHTS = [0.2, 0.3, 0.1, 0.1, 0.3]\n",
    "\n",
    "UPCONV = True    # True to use Up-Convolutuin (=TransposedConvolution), False to use Up-Sampling\n",
    "PATCH_SZ = 160   # should divide by 16\n",
    "\n",
    "N_EPOCHS = 150\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "TRAIN_SZ = 32*BATCH_SIZE  # train size (for one epoch)\n",
    "VAL_SZ = 1024    # validation size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013857,
     "end_time": "2021-09-08T05:25:12.798074",
     "exception": false,
     "start_time": "2021-09-08T05:25:12.784217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create a function generating network with given architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:37:02.736397Z",
     "iopub.status.busy": "2022-05-28T19:37:02.735411Z",
     "iopub.status.idle": "2022-05-28T19:37:02.772558Z",
     "shell.execute_reply": "2022-05-28T19:37:02.771607Z",
     "shell.execute_reply.started": "2022-05-28T19:37:02.736352Z"
    },
    "papermill": {
     "duration": 0.02778,
     "end_time": "2021-09-08T05:25:12.840026",
     "exception": false,
     "start_time": "2021-09-08T05:25:12.812246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unet_model(n_classes=5, im_sz=160, n_channels=8, n_filters_start=32, growth_factor=2, upconv=True,\n",
    "               class_weights=[0.2, 0.3, 0.1, 0.1, 0.3]):\n",
    "    droprate=0.25\n",
    "    n_filters = n_filters_start\n",
    "    inputs = Input((im_sz, im_sz, n_channels))\n",
    "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    pool1 = BatchNormalization()(pool1)\n",
    "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(droprate)(pool2)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    pool2 = BatchNormalization()(pool2)\n",
    "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(droprate)(pool3)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    pool3 = BatchNormalization()(pool3)\n",
    "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_0)\n",
    "    pool4_1 = MaxPooling2D(pool_size=(2, 2))(conv4_0)\n",
    "    pool4_1 = Dropout(droprate)(pool4_1)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    pool4_1 = BatchNormalization()(pool4_1)\n",
    "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_1)\n",
    "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_1)\n",
    "    pool4_2 = MaxPooling2D(pool_size=(2, 2))(conv4_1)\n",
    "    pool4_2 = Dropout(droprate)(pool4_2)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_2)\n",
    "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up6_1 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv5), conv4_1])\n",
    "    else:\n",
    "        up6_1 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4_1])\n",
    "    up6_1 = BatchNormalization()(up6_1)\n",
    "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_1)\n",
    "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_1)\n",
    "    conv6_1 = Dropout(droprate)(conv6_1)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up6_2 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_1), conv4_0])\n",
    "    else:\n",
    "        up6_2 = concatenate([UpSampling2D(size=(2, 2))(conv6_1), conv4_0])\n",
    "    up6_2 = BatchNormalization()(up6_2)\n",
    "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_2)\n",
    "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_2)\n",
    "    conv6_2 = Dropout(droprate)(conv6_2)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up7 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_2), conv3])\n",
    "    else:\n",
    "        up7 = concatenate([UpSampling2D(size=(2, 2))(conv6_2), conv3])\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = Dropout(droprate)(conv7)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up8 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv7), conv2])\n",
    "    else:\n",
    "        up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2])\n",
    "    up8 = BatchNormalization()(up8)\n",
    "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = Dropout(droprate)(conv8)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up9 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv8), conv1])\n",
    "    else:\n",
    "        up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1])\n",
    "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(n_classes, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    def weighted_binary_crossentropy(y_true, y_pred):\n",
    "        class_loglosses = K.mean(K.binary_crossentropy(y_true, y_pred), axis=[0, 1, 2])\n",
    "        return K.sum(class_loglosses * K.constant(class_weights))\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss=weighted_binary_crossentropy)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014417,
     "end_time": "2021-09-08T05:25:12.86881",
     "exception": false,
     "start_time": "2021-09-08T05:25:12.854393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is recommended not to feed whole satellite images to the network. <br>\n",
    "Instead, resample small patches of size $160 \\times 160$ and train the model with such samples. <br>\n",
    "This is a common practice in image segmentation.\n",
    "\n",
    "Create U-Net model using function `unet_model()` and see its summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:37:05.527211Z",
     "iopub.status.busy": "2022-05-28T19:37:05.526823Z",
     "iopub.status.idle": "2022-05-28T19:37:09.090554Z",
     "shell.execute_reply": "2022-05-28T19:37:09.089618Z",
     "shell.execute_reply.started": "2022-05-28T19:37:05.527180Z"
    },
    "papermill": {
     "duration": 2.164307,
     "end_time": "2021-09-08T05:25:15.047511",
     "exception": false,
     "start_time": "2021-09-08T05:25:12.883204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = unet_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014903,
     "end_time": "2021-09-08T05:25:15.077723",
     "exception": false,
     "start_time": "2021-09-08T05:25:15.06282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The output is created with 5 channels - one per segmentation class. Each channel will contain probabilities of pixel belonging to the corresponding class.\n",
    "\n",
    "Plot the neural network architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-05-28T19:37:09.092883Z",
     "iopub.status.busy": "2022-05-28T19:37:09.092287Z",
     "iopub.status.idle": "2022-05-28T19:37:10.389957Z",
     "shell.execute_reply": "2022-05-28T19:37:10.388885Z",
     "shell.execute_reply.started": "2022-05-28T19:37:09.092847Z"
    },
    "papermill": {
     "duration": 0.557034,
     "end_time": "2021-09-08T05:25:15.649802",
     "exception": false,
     "start_time": "2021-09-08T05:25:15.092768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018281,
     "end_time": "2021-09-08T05:25:15.686122",
     "exception": false,
     "start_time": "2021-09-08T05:25:15.667841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before training network normalize the images, so that all values are in [-1.0,1.0]. <br>\n",
    "Create function that does that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:37:13.183776Z",
     "iopub.status.busy": "2022-05-28T19:37:13.183348Z",
     "iopub.status.idle": "2022-05-28T19:37:13.189807Z",
     "shell.execute_reply": "2022-05-28T19:37:13.188875Z",
     "shell.execute_reply.started": "2022-05-28T19:37:13.183734Z"
    },
    "papermill": {
     "duration": 0.026858,
     "end_time": "2021-09-08T05:25:15.73099",
     "exception": false,
     "start_time": "2021-09-08T05:25:15.704132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    min = img.min()\n",
    "    max = img.max()\n",
    "    return 2.0 * (img - min) / (max - min) - 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017885,
     "end_time": "2021-09-08T05:25:15.766872",
     "exception": false,
     "start_time": "2021-09-08T05:25:15.748987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Read train data, normalize it and make channels last. Split validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:37:16.488063Z",
     "iopub.status.busy": "2022-05-28T19:37:16.487650Z",
     "iopub.status.idle": "2022-05-28T19:37:22.119765Z",
     "shell.execute_reply": "2022-05-28T19:37:22.118728Z",
     "shell.execute_reply.started": "2022-05-28T19:37:16.488020Z"
    },
    "papermill": {
     "duration": 5.307137,
     "end_time": "2021-09-08T05:25:21.092722",
     "exception": false,
     "start_time": "2021-09-08T05:25:15.785585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all availiable ids: from \"01\" to \"24\":\n",
    "trainIds = [str(i).zfill(2) for i in range(1, 25)]  \n",
    "\n",
    "X_DICT_TRAIN = dict()\n",
    "Y_DICT_TRAIN = dict()\n",
    "X_DICT_VALIDATION = dict()\n",
    "Y_DICT_VALIDATION = dict()\n",
    "\n",
    "print('Reading images')\n",
    "for img_id in trainIds:\n",
    "    img_m = normalize(tiff.imread(f'{DATA_PATH_PREFIX}/mband/{img_id}.tif').transpose([1, 2, 0]))\n",
    "    mask = tiff.imread(f'{DATA_PATH_PREFIX}/gt_mband/{img_id}.tif').transpose([1, 2, 0]) / 255\n",
    "    train_xsz = int(0.75 * img_m.shape[0])  # use 75% of image as train and 25% for validation\n",
    "    X_DICT_TRAIN[img_id] = img_m[:train_xsz, :, :]\n",
    "    Y_DICT_TRAIN[img_id] = mask[:train_xsz, :, :]\n",
    "    X_DICT_VALIDATION[img_id] = img_m[train_xsz:, :, :]\n",
    "    Y_DICT_VALIDATION[img_id] = mask[train_xsz:, :, :]\n",
    "    print(img_id + ' read')\n",
    "print('Images were read')\n",
    "\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023695,
     "end_time": "2021-09-08T05:25:21.140231",
     "exception": false,
     "start_time": "2021-09-08T05:25:21.116536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We need to prepare 160x160 patches from both train and validation data to fit the model.\n",
    "\n",
    "The following function `get_rand_patch()` picks random patch from an image and corresponding mask.\n",
    "Then function `get_patches()` resamples patches from the train or validataion set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:37:23.885148Z",
     "iopub.status.busy": "2022-05-28T19:37:23.884030Z",
     "iopub.status.idle": "2022-05-28T19:37:23.903445Z",
     "shell.execute_reply": "2022-05-28T19:37:23.902381Z",
     "shell.execute_reply.started": "2022-05-28T19:37:23.885094Z"
    },
    "papermill": {
     "duration": 0.035474,
     "end_time": "2021-09-08T05:25:21.19778",
     "exception": false,
     "start_time": "2021-09-08T05:25:21.162306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_rand_patch(img, mask, sz=160):\n",
    "    \"\"\"\n",
    "    :param img: ndarray with shape (x_sz, y_sz, num_channels)\n",
    "    :param mask: binary ndarray with shape (x_sz, y_sz, num_classes)\n",
    "    :param sz: size of random patch\n",
    "    :return: patch with shape (sz, sz, num_channels)\n",
    "    \"\"\"\n",
    "    assert len(img.shape) == 3 and img.shape[0] > sz and img.shape[1] > sz and img.shape[0:2] == mask.shape[0:2]\n",
    "    xc = random.randint(0, img.shape[0] - sz)\n",
    "    yc = random.randint(0, img.shape[1] - sz)\n",
    "    patch_img = img[xc:(xc + sz), yc:(yc + sz)]\n",
    "    patch_mask = mask[xc:(xc + sz), yc:(yc + sz)]\n",
    "\n",
    "    random_transformation = np.random.randint(1,8)\n",
    "    if random_transformation == 1:  \n",
    "        patch_img = patch_img[::-1,:,:]\n",
    "        patch_mask = patch_mask[::-1,:,:]\n",
    "    elif random_transformation == 2:    \n",
    "        patch_img = patch_img[:,::-1,:]\n",
    "        patch_mask = patch_mask[:,::-1,:]\n",
    "    elif random_transformation == 3:   \n",
    "        patch_img = patch_img.transpose([1,0,2])\n",
    "        patch_mask = patch_mask.transpose([1,0,2])\n",
    "    elif random_transformation == 4:\n",
    "        patch_img = np.rot90(patch_img, 1)\n",
    "        patch_mask = np.rot90(patch_mask, 1)\n",
    "    elif random_transformation == 5:\n",
    "        patch_img = np.rot90(patch_img, 2)\n",
    "        patch_mask = np.rot90(patch_mask, 2)\n",
    "    elif random_transformation == 6:\n",
    "        patch_img = np.rot90(patch_img, 3)\n",
    "        patch_mask = np.rot90(patch_mask, 3)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return patch_img, patch_mask\n",
    "\n",
    "\n",
    "def get_patches(x_dict, y_dict, n_patches, sz=160):\n",
    "    x = list()\n",
    "    y = list()\n",
    "    total_patches = 0\n",
    "    while total_patches < n_patches:\n",
    "        img_id = random.sample(x_dict.keys(), 1)[0]\n",
    "        img = x_dict[img_id]\n",
    "        mask = y_dict[img_id]\n",
    "        img_patch, mask_patch = get_rand_patch(img, mask, sz)\n",
    "        x.append(img_patch)\n",
    "        y.append(mask_patch)\n",
    "        total_patches += 1\n",
    "    print('Generated {} patches'.format(total_patches))\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# generator\n",
    "def gen_patches(x_dict, y_dict, n_patches, sz=PATCH_SZ):\n",
    "    while(True):\n",
    "        gc.collect()\n",
    "        yield get_patches(x_dict, y_dict, n_patches, sz=PATCH_SZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024986,
     "end_time": "2021-09-08T05:25:21.247596",
     "exception": false,
     "start_time": "2021-09-08T05:25:21.22261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create path for weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T18:48:59.195202Z",
     "iopub.status.busy": "2022-05-28T18:48:59.194852Z",
     "iopub.status.idle": "2022-05-28T18:48:59.200322Z",
     "shell.execute_reply": "2022-05-28T18:48:59.199332Z",
     "shell.execute_reply.started": "2022-05-28T18:48:59.195171Z"
    },
    "papermill": {
     "duration": 0.032941,
     "end_time": "2021-09-08T05:25:21.305627",
     "exception": false,
     "start_time": "2021-09-08T05:25:21.272686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_path = 'weights'\n",
    "if not os.path.exists(weights_path):\n",
    "    os.makedirs(weights_path)\n",
    "weights_path += '/unet_weights.hdf5'\n",
    "\n",
    "if os.path.isfile(weights_path):\n",
    "   model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024,
     "end_time": "2021-09-08T05:25:21.353916",
     "exception": false,
     "start_time": "2021-09-08T05:25:21.329916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Train network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T18:49:01.375361Z",
     "iopub.status.busy": "2022-05-28T18:49:01.375012Z",
     "iopub.status.idle": "2022-05-28T18:49:21.222284Z",
     "shell.execute_reply": "2022-05-28T18:49:21.221131Z",
     "shell.execute_reply.started": "2022-05-28T18:49:01.375331Z"
    },
    "papermill": {
     "duration": 503.632964,
     "end_time": "2021-09-08T05:33:45.009176",
     "exception": false,
     "start_time": "2021-09-08T05:25:21.376212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"start training net\")\n",
    "\n",
    "x_val, y_val = get_patches(X_DICT_VALIDATION, Y_DICT_VALIDATION, n_patches=VAL_SZ, sz=PATCH_SZ)\n",
    "# callbacks = []\n",
    "# callbacks.append(ModelCheckpoint('./weights/', monitor='val_loss', save_best_only=True))\n",
    "# callbacks.append(CSVLogger('log_unet.csv', append=True, separator=';'))\n",
    "# callbacks.append(TensorBoard(log_dir='./tensorboard_unet/', write_graph=True, write_images=True))\n",
    "# callbacks.append(EarlyStopping(patience=5, verbose=1, restore_best_weights=True))\n",
    "# callbacks.append(ReduceLROnPlateau(patience=3, verbose=1))\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "train_gen = gen_patches(X_DICT_TRAIN, Y_DICT_TRAIN, n_patches=BATCH_SIZE, sz=PATCH_SZ)\n",
    "model.fit(train_gen, steps_per_epoch = TRAIN_SZ//BATCH_SIZE, \n",
    "          batch_size=BATCH_SIZE, epochs=N_EPOCHS,\n",
    "              verbose=2, shuffle=False,\n",
    "              callbacks=[model_checkpoint],\n",
    "              validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:37:29.250990Z",
     "iopub.status.busy": "2022-05-28T19:37:29.250616Z",
     "iopub.status.idle": "2022-05-28T19:37:29.276544Z",
     "shell.execute_reply": "2022-05-28T19:37:29.275147Z",
     "shell.execute_reply.started": "2022-05-28T19:37:29.250960Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2-ая модель, обучается меньше и распознает больше полей (crops)\n",
    "def unet_crops(n_classes=N_CLASSES, im_sz=PATCH_SZ, n_channels=N_BANDS, \n",
    "               n_filters_start=32, depth=4, growth_factor=2, upconv=UPCONV,\n",
    "               class_weights=CLASS_WEIGHTS):\n",
    "    inputs = Input((im_sz, im_sz, n_channels))\n",
    "    x = inputs\n",
    "\n",
    "    conv1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "    conv1 = Dropout(0.2)(conv1)  \n",
    "    conv1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool1)\n",
    "    conv2 = Dropout(0.2)(conv2)  \n",
    "    conv2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "     \n",
    "    conv3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool2)\n",
    "    conv3 = Dropout(0.2)(conv3)\n",
    "    conv3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "     \n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool3)\n",
    "    conv4 = Dropout(0.2)(conv4)\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "     \n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool4)\n",
    "    conv5 = Dropout(0.3)(conv5)\n",
    "    conv5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv5)\n",
    "    \n",
    "    up6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "    up6 = concatenate([up6, conv4])\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up6)\n",
    "    conv6 = Dropout(0.2)(conv6)\n",
    "    conv6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    "     \n",
    "    up7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = concatenate([up7, conv3])\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up7)\n",
    "    conv7 = Dropout(0.2)(conv7)\n",
    "    conv7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    "     \n",
    "    up8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "    up8 = concatenate([up8, conv2])\n",
    "    conv8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up8)\n",
    "    conv8 = Dropout(0.2)(conv8) \n",
    "    conv8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv8)\n",
    "     \n",
    "    up9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "    up9 = concatenate([up9, conv1], axis=3)\n",
    "    conv9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up9)\n",
    "    conv9 = Dropout(0.2)(conv9)\n",
    "    conv9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv9)\n",
    "     \n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # use weighted binary crossentropy as loss func\n",
    "    def weighted_binary_crossentropy(y_true, y_pred):\n",
    "        class_loglosses = K.mean(K.binary_crossentropy(y_true, y_pred), axis=[0, 1, 2])\n",
    "        return K.sum(class_loglosses * K.constant(class_weights))\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss=weighted_binary_crossentropy)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:37:32.463416Z",
     "iopub.status.busy": "2022-05-28T19:37:32.462764Z",
     "iopub.status.idle": "2022-05-28T19:37:32.700384Z",
     "shell.execute_reply": "2022-05-28T19:37:32.699321Z",
     "shell.execute_reply.started": "2022-05-28T19:37:32.463381Z"
    }
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "TRAIN_SZ = 8*BATCH_SIZE\n",
    "VAL_SZ = 1024\n",
    "\n",
    "model_crops = unet_crops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:37:33.791512Z",
     "iopub.status.busy": "2022-05-28T19:37:33.790555Z",
     "iopub.status.idle": "2022-05-28T19:37:33.801205Z",
     "shell.execute_reply": "2022-05-28T19:37:33.799655Z",
     "shell.execute_reply.started": "2022-05-28T19:37:33.791472Z"
    }
   },
   "outputs": [],
   "source": [
    "model_crops.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:37:37.063072Z",
     "iopub.status.busy": "2022-05-28T19:37:37.062398Z",
     "iopub.status.idle": "2022-05-28T19:37:37.376352Z",
     "shell.execute_reply": "2022-05-28T19:37:37.375236Z",
     "shell.execute_reply.started": "2022-05-28T19:37:37.063030Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(model_crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T18:58:57.60218Z",
     "iopub.status.busy": "2022-05-28T18:58:57.601792Z",
     "iopub.status.idle": "2022-05-28T19:01:29.206825Z",
     "shell.execute_reply": "2022-05-28T19:01:29.205817Z",
     "shell.execute_reply.started": "2022-05-28T18:58:57.602144Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"start training net\")\n",
    "\n",
    "x_val, y_val = get_patches(X_DICT_VALIDATION, Y_DICT_VALIDATION, n_patches=VAL_SZ, sz=PATCH_SZ)\n",
    "callbacks = []\n",
    "callbacks.append(ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=True))\n",
    "callbacks.append(CSVLogger('log_unet.csv', append=True, separator=';'))\n",
    "#callbacks.append(TensorBoard(log_dir='./tensorboard_unet/', write_graph=True, write_images=True))\n",
    "callbacks.append(EarlyStopping(patience=5, verbose=1))\n",
    "callbacks.append(ReduceLROnPlateau(patience=3, verbose=1))\n",
    "\n",
    "train_gen = gen_patches(X_DICT_TRAIN, Y_DICT_TRAIN, n_patches=BATCH_SIZE, sz=PATCH_SZ)\n",
    "model_crops.fit(train_gen, steps_per_epoch = TRAIN_SZ//BATCH_SIZE, \n",
    "          batch_size=BATCH_SIZE, epochs=N_EPOCHS,\n",
    "              verbose=2, shuffle=False,\n",
    "              callbacks=callbacks,\n",
    "              validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.154554,
     "end_time": "2021-09-08T05:33:45.320743",
     "exception": false,
     "start_time": "2021-09-08T05:33:45.166189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction\n",
    "\n",
    "The following function takes: \n",
    "- image *'x'* \n",
    "- trained model \n",
    "- patch size \n",
    "- number of classes\n",
    "\n",
    "It returns predicted probabilities of each class for every pixel of *'x'* in array with shape `(extended_height, extended_width, n_classes)`, where `extended_height` and `extended_width` are extended dimensions of `x` that make whole number of patches in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:37:44.202363Z",
     "iopub.status.busy": "2022-05-28T19:37:44.201914Z",
     "iopub.status.idle": "2022-05-28T19:37:44.229927Z",
     "shell.execute_reply": "2022-05-28T19:37:44.229023Z",
     "shell.execute_reply.started": "2022-05-28T19:37:44.202292Z"
    }
   },
   "outputs": [],
   "source": [
    "def start_points(size, split_size, overlap=0):\n",
    "    points = [0]\n",
    "    stride = int(split_size * (1-overlap))\n",
    "    counter = 1\n",
    "    while True:\n",
    "        pt = stride * counter\n",
    "        if pt + split_size >= size:\n",
    "            points.append(size - split_size)\n",
    "            break\n",
    "        else:\n",
    "            points.append(pt)\n",
    "        counter += 1\n",
    "    return points\n",
    "\n",
    "def predict_again(x, model, patch_sz=PATCH_SZ, n_classes=N_CLASSES):\n",
    "    img_height = x.shape[0]\n",
    "    img_width = x.shape[1]\n",
    "    n_channels = x.shape[2]\n",
    "\n",
    "    # make extended img so that it contains integer number of patches\n",
    "    npatches_vertical = math.ceil(img_height/patch_sz)\n",
    "    npatches_horizontal = math.ceil(img_width/patch_sz)\n",
    "    extended_height = patch_sz * npatches_vertical\n",
    "    extended_width = patch_sz * npatches_horizontal\n",
    "    ext_x = np.zeros(shape=(extended_height, extended_width, n_channels), dtype=np.float32)\n",
    "    # fill extended image with mirror reflections of neighbors:\n",
    "    ext_x[:img_height, :img_width, :] = x\n",
    "    for i in range(img_height, extended_height):\n",
    "        ext_x[i, :, :] = ext_x[2*img_height - i - 1, :, :]\n",
    "    for j in range(img_width, extended_width):\n",
    "        ext_x[:, j, :] = ext_x[:, 2*img_width - j - 1, :]\n",
    "    \n",
    "    predictions = []\n",
    "    for flip in [1,-1] :\n",
    "        for rot in range(4) :\n",
    "            ext = ext_x[::flip,:,:]\n",
    "            ext = np.rot90(ext, k=rot, axes=(0,1))\n",
    "            \n",
    "            # now assemble all patches in one array\n",
    "            patches_list = []\n",
    "            for i in range(0, npatches_vertical):\n",
    "                for j in range(0, npatches_horizontal):\n",
    "                    x0, x1 = i * patch_sz, (i + 1) * patch_sz\n",
    "                    y0, y1 = j * patch_sz, (j + 1) * patch_sz\n",
    "                    patches_list.append(ext[x0:x1, y0:y1, :])\n",
    "            # model.predict() needs numpy array rather than a list\n",
    "            patches_array = np.asarray(patches_list)\n",
    "            # predictions:\n",
    "            patches_predict = model.predict(patches_array, batch_size=4)\n",
    "            prediction = np.zeros(shape=(extended_height, extended_width, n_classes), dtype=np.float32)\n",
    "            for k in range(patches_predict.shape[0]):\n",
    "                i = k // npatches_horizontal\n",
    "                j = k % npatches_vertical\n",
    "                x0, x1 = i * patch_sz, (i + 1) * patch_sz\n",
    "                y0, y1 = j * patch_sz, (j + 1) * patch_sz\n",
    "                prediction[x0:x1, y0:y1, :] = patches_predict[k, :, :, :]\n",
    "\n",
    "            # now assemble all patches in one array\n",
    "            patches_list_overlap = []\n",
    "            X_points = start_points(extended_width, patch_sz, 0.5)\n",
    "            Y_points = start_points(extended_height, patch_sz, 0.5)\n",
    "            for i in Y_points:\n",
    "                for j in X_points:\n",
    "                    split = ext[i:i+patch_sz, j:j+patch_sz]\n",
    "                    patches_list_overlap.append(split)\n",
    "            # model.predict() needs numpy array rather than a list\n",
    "            patches_array_overlap = np.asarray(patches_list_overlap)\n",
    "            # predictions:\n",
    "            patches_predict_overlap = model.predict(patches_array_overlap, batch_size=4)\n",
    "            for k in range(patches_predict_overlap.shape[0]):\n",
    "                i = k // (2*npatches_horizontal-1)\n",
    "                j = k % (2*npatches_vertical-1)\n",
    "                x0 = int(i * patch_sz / 2)\n",
    "                y0 = int(j * patch_sz / 2)\n",
    "                x1, y1 = x0 + patch_sz, y0 + patch_sz\n",
    "                prediction[x0:x1, y0:y1, :] = 0.5*patches_predict_overlap[k, :, :, :] + 0.5*prediction[x0:x1, y0:y1, :]\n",
    "            \n",
    "            pred = np.rot90(prediction, k=4-rot, axes=(0,1))\n",
    "            pred = pred[::flip,:,:]\n",
    "#             tiff.imshow(picture_from_mask(pred.transpose([2,0,1]), threshold=0.3))\n",
    "            predictions.append(pred)\n",
    "    predictions = np.asarray(predictions)\n",
    "    prediction = np.mean(predictions, axis=0)\n",
    "    return prediction[:img_height, :img_width, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.163624,
     "end_time": "2021-09-08T05:33:45.983794",
     "exception": false,
     "start_time": "2021-09-08T05:33:45.82017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that method `predict()` in the cell above uses `batch_size`. Batch prediction is usually used when data set to be predicted is very large and may not fit in memory. In such case prediction will be done batch by batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.157813,
     "end_time": "2021-09-08T05:33:46.298815",
     "exception": false,
     "start_time": "2021-09-08T05:33:46.141002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Show image of the created mask. <br>\n",
    "On this image use color codes of the first 5 colors for the 5 classes. <br>\n",
    "Create function that takes a mask created by *'predict()'* and a threshold and returns an RGB file that can be shown by *'imshow()'*. <br>\n",
    "\n",
    "In function *'picture_from_mask()'* created below:\n",
    "- Dictionary variable *'colors'* contains first 5 colors corresponding to the 5 classes of objects. Color of each class is defined as combination of 3 basic colors\n",
    "- Dictionary *'z_order'* creates special order of classes in which the mask-image is created. If the same pixel has high enough probability of belonging to several classes then the pixel is marked as highest of them in *'z_order'*. Basically, this means that in the loop over *'z_order'* color of the next significant class replaces the color of the previous one.\n",
    "- A class of a pixel is considered \"significant\" if probability of that class is greater than \"threshold\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:37:48.087966Z",
     "iopub.status.busy": "2022-05-28T19:37:48.087207Z",
     "iopub.status.idle": "2022-05-28T19:37:48.096704Z",
     "shell.execute_reply": "2022-05-28T19:37:48.095762Z",
     "shell.execute_reply.started": "2022-05-28T19:37:48.087922Z"
    },
    "papermill": {
     "duration": 0.16964,
     "end_time": "2021-09-08T05:33:46.626065",
     "exception": false,
     "start_time": "2021-09-08T05:33:46.456425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def picture_from_mask(mask, threshold=0):\n",
    "    colors = {\n",
    "        0: [150, 150, 150],  # Buildings\n",
    "        1: [223, 194, 125],  # Roads & Tracks\n",
    "        2: [27, 120, 55],    # Trees\n",
    "        3: [166, 219, 160],  # Crops\n",
    "        4: [116, 173, 209]   # Water\n",
    "    }\n",
    "    z_order = {\n",
    "        1: 3,\n",
    "        2: 4,\n",
    "        3: 0,\n",
    "        4: 1,\n",
    "        5: 2\n",
    "    }\n",
    "    pict = 255*np.ones(shape=(3, mask.shape[1], mask.shape[2]), dtype=np.uint8)\n",
    "    for i in range(1, 6):\n",
    "        cl = z_order[i]\n",
    "        for ch in range(3):\n",
    "            pict[ch,:,:][mask[cl,:,:] > threshold] = colors[cl][ch]\n",
    "    return pict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.1607,
     "end_time": "2021-09-08T05:33:46.944149",
     "exception": false,
     "start_time": "2021-09-08T05:33:46.783449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Read test image, normalize it and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-28T19:53:33.908124Z",
     "iopub.status.busy": "2022-05-28T19:53:33.907305Z",
     "iopub.status.idle": "2022-05-28T19:53:40.482048Z",
     "shell.execute_reply": "2022-05-28T19:53:40.481203Z",
     "shell.execute_reply.started": "2022-05-28T19:53:33.908089Z"
    },
    "papermill": {
     "duration": 1.650343,
     "end_time": "2021-09-08T05:33:48.754707",
     "exception": false,
     "start_time": "2021-09-08T05:33:47.104364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_id = 'test'\n",
    "img = normalize(tiff.imread(f'{DATA_PATH_PREFIX}/mband/{test_id}.tif').transpose([1,2,0]))   # make channels last\n",
    "my_mask = predict_again(img, model, patch_sz=PATCH_SZ, n_classes=N_CLASSES).transpose([2,0,1])\n",
    "mask = predict_again(img, model_crops, patch_sz=PATCH_SZ, n_classes=N_CLASSES).transpose([2,0,1])  # make channels first\n",
    "map_ = picture_from_mask((mask+my_mask)/2, threshold=0.3)\n",
    "tiff.imsave('result.tif', (255*(mask+my_mask)/2).astype('uint8'))\n",
    "tiff.imsave('map.tif', map_.astype('uint8'))\n",
    "tiff.imshow(map_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
